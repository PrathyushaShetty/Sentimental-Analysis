{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69016a3a-a39f-4d6f-919a-0e757f274c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\asshe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\asshe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download the punkt tokenizer models\n",
    "nltk.download('punkt')\n",
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbb3f283-d0b7-46b9-9c85-17aba1e46352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\asshe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\asshe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\asshe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2108843537414966\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "         Acceptance          0.00      0.00      0.00         2\n",
      "           Admiration        0.00      0.00      0.00         1\n",
      "        Admiration           0.00      0.00      0.00         1\n",
      "         Affection           1.00      1.00      1.00         1\n",
      "      Ambivalence            1.00      1.00      1.00         1\n",
      "         Anger               0.00      0.00      0.00         1\n",
      "        Anticipation         0.00      0.00      0.00         1\n",
      "        Arousal              0.38      1.00      0.55         3\n",
      "                  Awe        0.00      0.00      0.00         1\n",
      "         Awe                 0.00      0.00      0.00         1\n",
      "                  Bad        1.00      1.00      1.00         1\n",
      "             Betrayal        0.00      0.00      0.00         2\n",
      "        Betrayal             0.00      0.00      0.00         1\n",
      "         Bitter              1.00      1.00      1.00         1\n",
      "           Bitterness        1.00      1.00      1.00         1\n",
      "          Bittersweet        0.00      0.00      0.00         1\n",
      "              Boredom        0.00      0.00      0.00         1\n",
      "         Calmness            1.00      1.00      1.00         1\n",
      "          Captivation        0.00      0.00      0.00         1\n",
      "     Celestial Wonder        0.00      0.00      0.00         1\n",
      "             Colorful        0.00      0.00      0.00         1\n",
      "      Confusion              1.00      0.67      0.80         3\n",
      "           Connection        0.00      0.00      0.00         1\n",
      "        Contemplation        0.00      0.00      0.00         1\n",
      "          Contentment        0.00      0.00      0.00         3\n",
      "        Contentment          0.00      0.00      0.00         1\n",
      "         Coziness            1.00      1.00      1.00         1\n",
      "         Creativity          0.00      0.00      0.00         1\n",
      "            Curiosity        0.00      0.00      0.00         2\n",
      "          Curiosity          0.00      0.00      0.00         1\n",
      "      Curiosity              1.00      1.00      1.00         2\n",
      "           Desolation        0.00      0.00      0.00         1\n",
      "           Devastated        0.00      0.00      0.00         2\n",
      "              Disgust        0.00      0.00      0.00         1\n",
      "         Disgust             0.00      0.00      0.00         2\n",
      "        Elation              1.00      0.33      0.50         3\n",
      "             Elegance        0.00      0.00      0.00         1\n",
      "          Embarrassed        0.00      0.00      0.00         1\n",
      "       EmotionalStorm        0.00      0.00      0.00         1\n",
      "        Empowerment          1.00      1.00      1.00         1\n",
      "         Enjoyment           0.00      0.00      0.00         2\n",
      "           Enthusiasm        0.00      0.00      0.00         1\n",
      "              Envious        0.00      0.00      0.00         2\n",
      "  Envisioning History        0.00      0.00      0.00         1\n",
      "         Euphoria            0.00      0.00      0.00         1\n",
      "           Excitement        0.00      0.00      0.00         3\n",
      "         Excitement          0.25      0.33      0.29         3\n",
      "        Excitement           0.00      0.00      0.00         1\n",
      "         Fear                0.00      0.00      0.00         1\n",
      "              Fearful        1.00      1.00      1.00         1\n",
      "           Frustrated        1.00      1.00      1.00         1\n",
      "          Frustration        0.00      0.00      0.00         3\n",
      "         Fulfillment         0.00      0.00      0.00         2\n",
      "             Grateful        1.00      1.00      1.00         1\n",
      "      Grief                  1.00      1.00      1.00         1\n",
      "                Happy        0.00      0.00      0.00         6\n",
      "                 Hate        0.67      1.00      0.80         2\n",
      "           Heartbreak        0.00      0.00      0.00         2\n",
      "              Hopeful        1.00      1.00      1.00         1\n",
      "        InnerJourney         0.00      0.00      0.00         1\n",
      "        Inspiration          0.00      0.00      0.00         1\n",
      "             Inspired        1.00      1.00      1.00         1\n",
      "            Isolation        0.00      0.00      0.00         1\n",
      "          Jealousy           0.00      0.00      0.00         1\n",
      "                  Joy        0.00      0.00      0.00         8\n",
      "         Joy                 0.50      1.00      0.67         1\n",
      "        JoyfulReunion        0.00      0.00      0.00         1\n",
      "         Kind                0.00      0.00      0.00         1\n",
      "           Loneliness        1.00      1.00      1.00         1\n",
      "      Loneliness             0.00      0.00      0.00         1\n",
      "             LostLove        0.00      0.00      0.00         1\n",
      "      Melancholy             0.00      0.00      0.00         2\n",
      "       Miscalculation        0.00      0.00      0.00         1\n",
      "              Neutral        0.00      0.00      0.00         1\n",
      "        Nostalgia            0.00      0.00      0.00         1\n",
      "      Nostalgia              0.00      0.00      0.00         1\n",
      "      Numbness               0.00      0.00      0.00         1\n",
      "          Overwhelmed        0.00      0.00      0.00         1\n",
      "              Playful        1.00      0.50      0.67         2\n",
      "            Positive         0.00      0.00      0.00         9\n",
      "                Proud        1.00      1.00      1.00         1\n",
      "        Reflection           0.00      0.00      0.00         1\n",
      "       Regret                0.50      1.00      0.67         1\n",
      "           Resilience        0.00      0.00      0.00         1\n",
      "            Reverence        0.00      0.00      0.00         1\n",
      "         Sadness             0.00      0.00      0.00         2\n",
      "        Satisfaction         0.00      0.00      0.00         1\n",
      "             Serenity        0.00      0.00      0.00         2\n",
      "      Serenity               1.00      0.50      0.67         2\n",
      "             Solitude        0.00      0.00      0.00         1\n",
      "          Sorrow             0.00      0.00      0.00         1\n",
      "         Spark               0.00      0.00      0.00         1\n",
      "         Surprise            0.00      0.00      0.00         1\n",
      "        Thrill               0.00      0.00      0.00         1\n",
      "             Vibrancy        0.00      0.00      0.00         1\n",
      " Whispers of the Past        0.00      0.00      0.00         1\n",
      "                 Zest        0.00      0.00      0.00         1\n",
      "\n",
      "             micro avg       0.57      0.21      0.31       147\n",
      "             macro avg       0.24      0.24      0.23       147\n",
      "          weighted avg       0.22      0.21      0.20       147\n",
      "\n",
      "The predicted sentiment for the statement is:  Euphoria      \n",
      "Statement: I love this product!\n",
      "Predicted Sentiment:  Love         \n",
      "Statement: This is the worst thing ever.\n",
      "Predicted Sentiment:  Positive  \n",
      "Statement: Absolutely fantastic!\n",
      "Predicted Sentiment:  Neutral \n",
      "Statement: I hate this product.\n",
      "Predicted Sentiment:  Euphoria      \n",
      "The predicted sentiment for the statement is:  Embarrassed \n",
      "Prediction probabilities: [[0.00407366 0.00417024 0.00416967 0.00417823 0.0042087  0.00413446\n",
      "  0.00418401 0.00414783 0.00412302 0.00410216 0.00418557 0.0042069\n",
      "  0.00415554 0.00415358 0.00420628 0.00411632 0.00407032 0.00415788\n",
      "  0.00417314 0.00415736 0.00414655 0.00419835 0.00410523 0.00397801\n",
      "  0.00410311 0.00424679 0.00417924 0.0042067  0.00420888 0.00411308\n",
      "  0.0042125  0.00413229 0.00418505 0.00413527 0.00413428 0.00415095\n",
      "  0.00410113 0.00411346 0.00411919 0.00420162 0.00415811 0.00414382\n",
      "  0.00416942 0.00411524 0.0041703  0.00416997 0.00404856 0.00421038\n",
      "  0.0041995  0.00408738 0.00410386 0.00417764 0.00409027 0.00409209\n",
      "  0.00423427 0.00412253 0.0040953  0.0042003  0.0041106  0.00417325\n",
      "  0.0041648  0.00419057 0.00414813 0.00409873 0.00418598 0.00412814\n",
      "  0.00417013 0.0042276  0.00407627 0.00420631 0.00415809 0.00421828\n",
      "  0.0041985  0.00408134 0.00412219 0.00409987 0.00414904 0.00424664\n",
      "  0.00413751 0.0041718  0.00422241 0.00415323 0.00418384 0.00412128\n",
      "  0.00407223 0.00412583 0.00423108 0.00415119 0.00420757 0.00409478\n",
      "  0.00415203 0.0049849  0.00424623 0.00412671 0.00412179 0.00414608\n",
      "  0.00408612 0.00415901 0.00412263 0.00413474 0.00410359 0.0040981\n",
      "  0.00417987 0.00413187 0.00419594 0.00415472 0.0041281  0.00416408\n",
      "  0.00422231 0.00410603 0.0041053  0.00413768 0.0041811  0.00416889\n",
      "  0.00416451 0.00417631 0.00415381 0.0041877  0.00406006 0.00422342\n",
      "  0.00407499 0.00404253 0.00402659 0.00468626 0.00409923 0.00406406\n",
      "  0.00410883 0.00413413 0.00412798 0.00409733 0.00421563 0.00420531\n",
      "  0.00414347 0.00413329 0.00412625 0.00407215 0.00415553 0.00420264\n",
      "  0.00416595 0.00409625 0.00417391 0.00410851 0.00413709 0.00411509\n",
      "  0.00409145 0.00420933 0.00420234 0.0040914  0.00424306 0.00415303\n",
      "  0.00409149 0.00417549 0.0040919  0.00420781 0.00414318 0.00412495\n",
      "  0.00407152 0.00416225 0.00412217 0.00413437 0.00418696 0.00411426\n",
      "  0.00407428 0.00414585 0.00421037 0.00416166 0.00404266 0.00423469\n",
      "  0.00425884 0.00424394 0.00419119 0.00411752 0.00416228 0.00406806\n",
      "  0.00416359 0.00413557 0.00412323 0.0041114  0.00410482 0.00418797\n",
      "  0.00410016 0.00406362 0.00415658 0.00410061 0.00414484 0.00424141\n",
      "  0.00409912 0.00414489 0.0042202  0.00415488 0.00410863 0.00417411\n",
      "  0.00407764 0.00408625 0.00417444 0.00410768 0.00421191 0.00413572\n",
      "  0.00415283 0.0041518  0.00413385 0.00412061 0.00422677 0.00412854\n",
      "  0.00410008 0.00419365 0.00412624 0.00407095 0.00414348 0.00420669\n",
      "  0.00420371 0.00417273 0.0041291  0.00419567 0.00415588 0.00416471\n",
      "  0.00415078 0.00411498 0.00410389 0.00406662 0.00408546 0.00420763\n",
      "  0.0040671  0.00407937 0.00411322 0.00413812 0.00419937 0.0041591\n",
      "  0.0041302  0.00408196 0.00407645 0.00413413 0.00414313 0.00414101\n",
      "  0.00411924 0.0041032  0.00402714 0.00403364 0.0041341  0.00415717\n",
      "  0.00409886]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load your dataset\n",
    "file_path = r'C:\\Users\\asshe\\Desktop\\Sentiment analysis\\sentimentdataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean the 'Text' column\n",
    "df['Cleaned_Text'] = df['Text'].apply(lambda x: x.lower())  # Convert to lowercase\n",
    "\n",
    "# Tokenize, remove stopwords, and lemmatize\n",
    "df['Cleaned_Text'] = df['Cleaned_Text'].apply(lambda x: word_tokenize(x))\n",
    "df['Cleaned_Text'] = df['Cleaned_Text'].apply(lambda x: [word for word in x if word not in stopwords.words('english')])\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['Cleaned_Text'] = df['Cleaned_Text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "# Continue with your sentiment analysis...\n",
    "df['Cleaned_Text'] = df['Cleaned_Text'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Encode the sentiment labels\n",
    "le = LabelEncoder()\n",
    "df['Encoded_Sentiment'] = le.fit_transform(df['Sentiment'])\n",
    "\n",
    "# Vectorize the cleaned text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2), stop_words='english')\n",
    "X = vectorizer.fit_transform(df['Cleaned_Text'])\n",
    "\n",
    "# Define the target variable\n",
    "y = df['Encoded_Sentiment']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model with class weights\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "labels = sorted(set(y_test))  # Get unique labels in y_test\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, labels=labels, target_names=le.inverse_transform(labels)))\n",
    "\n",
    "# Save the vectorizer and model\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)\n",
    "\n",
    "with open('sentiment_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "# Load the vectorizer and model\n",
    "with open('tfidf_vectorizer.pkl', 'rb') as file:\n",
    "    loaded_vectorizer = pickle.load(file)\n",
    "\n",
    "with open('sentiment_model.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Sample preprocessing function\n",
    "def preprocess_text(text):\n",
    "    cleaned_text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    cleaned_text = re.sub(r'\\@\\w+|\\#', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', cleaned_text)\n",
    "    cleaned_text = cleaned_text.lower().split()\n",
    "    cleaned_text = [word for word in cleaned_text if word not in stopwords.words('english')]\n",
    "    cleaned_text = ' '.join(cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "def predict_sentiment(new_statement):\n",
    "    cleaned_statement = preprocess_text(new_statement)\n",
    "    transformed_statement = loaded_vectorizer.transform([cleaned_statement])\n",
    "    prediction = loaded_model.predict(transformed_statement)\n",
    "    sentiment_label = le.inverse_transform(prediction)\n",
    "    return sentiment_label[0]\n",
    "\n",
    "def predict_sentiment_with_proba(new_statement):\n",
    "    cleaned_statement = preprocess_text(new_statement)\n",
    "    transformed_statement = loaded_vectorizer.transform([cleaned_statement])\n",
    "    prediction_proba = loaded_model.predict_proba(transformed_statement)\n",
    "    sentiment_label = le.inverse_transform([prediction_proba.argmax()])\n",
    "    return sentiment_label[0], prediction_proba\n",
    "\n",
    "# Example usage\n",
    "new_statement = \"I hate this product!\"\n",
    "predicted_sentiment = predict_sentiment(new_statement)\n",
    "print(f\"The predicted sentiment for the statement is: {predicted_sentiment}\")\n",
    "\n",
    "test_statements = [\n",
    "    \"I love this product!\",\n",
    "    \"This is the worst thing ever.\",\n",
    "    \"Absolutely fantastic!\",\n",
    "    \"I hate this product.\"\n",
    "]\n",
    "\n",
    "for statement in test_statements:\n",
    "    print(f\"Statement: {statement}\")\n",
    "    print(f\"Predicted Sentiment: {predict_sentiment(statement)}\")\n",
    "\n",
    "# Example usage with probabilities\n",
    "predicted_sentiment, proba = predict_sentiment_with_proba(new_statement)\n",
    "print(f\"The predicted sentiment for the statement is: {predicted_sentiment}\")\n",
    "print(f\"Prediction probabilities: {proba}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bf8730a-25f7-4d10-b4b8-f60703356781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\asshe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\asshe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\asshe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Clean the 'Text' column\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCleaned_Text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mText\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mlower())  \u001b[38;5;66;03m# Convert to lowercase\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Tokenize, remove stopwords, and lemmatize\u001b[39;00m\n\u001b[0;32m     27\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCleaned_Text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCleaned_Text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: word_tokenize(x))\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Text'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load your dataset\n",
    "file_path = r'C:\\Users\\asshe\\Downloads\\twitter_training.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean the 'Text' column\n",
    "df['Cleaned_Text'] = df['Text'].apply(lambda x: x.lower())  # Convert to lowercase\n",
    "\n",
    "# Tokenize, remove stopwords, and lemmatize\n",
    "df['Cleaned_Text'] = df['Cleaned_Text'].apply(lambda x: word_tokenize(x))\n",
    "df['Cleaned_Text'] = df['Cleaned_Text'].apply(lambda x: [word for word in x if word not in stopwords.words('english')])\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['Cleaned_Text'] = df['Cleaned_Text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "# Continue with your sentiment analysis...\n",
    "df['Cleaned_Text'] = df['Cleaned_Text'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Encode the sentiment labels\n",
    "le = LabelEncoder()\n",
    "df['Encoded_Sentiment'] = le.fit_transform(df['Sentiment'])\n",
    "print(le.classes_)  # Print out the classes to ensure correct encoding\n",
    "\n",
    "# Vectorize the cleaned text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2), stop_words='english')\n",
    "X = vectorizer.fit_transform(df['Cleaned_Text'])\n",
    "\n",
    "# Define the target variable\n",
    "y = df['Encoded_Sentiment']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Hyperparameter tuning with GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from GridSearch\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "labels = sorted(set(y_test))  # Get unique labels in y_test\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, labels=labels, target_names=le.inverse_transform(labels)))\n",
    "\n",
    "# Save the vectorizer and model\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)\n",
    "\n",
    "with open('sentiment_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_rf_model, file)\n",
    "\n",
    "# Load the vectorizer and model\n",
    "with open('tfidf_vectorizer.pkl', 'rb') as file:\n",
    "    loaded_vectorizer = pickle.load(file)\n",
    "\n",
    "with open('sentiment_model.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Sample preprocessing function\n",
    "def preprocess_text(text):\n",
    "    cleaned_text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    cleaned_text = re.sub(r'\\@\\w+|\\#', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', cleaned_text)\n",
    "    cleaned_text = cleaned_text.lower().split()\n",
    "    cleaned_text = [word for word in cleaned_text if word not in stopwords.words('english')]\n",
    "    cleaned_text = ' '.join(cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "def predict_sentiment(new_statement):\n",
    "    cleaned_statement = preprocess_text(new_statement)\n",
    "    transformed_statement = loaded_vectorizer.transform([cleaned_statement])\n",
    "    prediction = loaded_model.predict(transformed_statement)\n",
    "    sentiment_label = le.inverse_transform(prediction)\n",
    "    return sentiment_label[0]\n",
    "\n",
    "def predict_sentiment_with_proba(new_statement):\n",
    "    cleaned_statement = preprocess_text(new_statement)\n",
    "    transformed_statement = loaded_vectorizer.transform([cleaned_statement])\n",
    "    prediction_proba = loaded_model.predict_proba(transformed_statement)\n",
    "    sentiment_label = le.inverse_transform([prediction_proba.argmax()])\n",
    "    return sentiment_label[0], prediction_proba\n",
    "\n",
    "# Example usage\n",
    "new_statement = \"I hate this product!\"\n",
    "predicted_sentiment, proba = predict_sentiment_with_proba(new_statement)\n",
    "print(f\"The predicted sentiment for the statement is: {predicted_sentiment}\")\n",
    "print(f\"Prediction probabilities: {proba}\")\n",
    "\n",
    "test_statements = [\n",
    "    \"I love this product!\",\n",
    "    \"This is the worst thing ever.\",\n",
    "    \"Absolutely fantastic!\",\n",
    "    \"I hate this product.\"\n",
    "]\n",
    "\n",
    "for statement in test_statements:\n",
    "    print(f\"Statement: {statement}\")\n",
    "    print(f\"Predicted Sentiment: {predict_sentiment(statement)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0b074d4-7e5d-4264-9ed5-4ac9444213cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\asshe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\asshe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\asshe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Acceptance   ' ' Acceptance      ' ' Accomplishment ' ' Admiration '\n",
      " ' Admiration   ' ' Admiration    ' ' Adoration    ' ' Adrenaline     '\n",
      " ' Adventure ' ' Affection    ' ' Amazement ' ' Ambivalence '\n",
      " ' Ambivalence     ' ' Amusement    ' ' Amusement     ' ' Anger        '\n",
      " ' Anticipation ' ' Anticipation  ' ' Anxiety   ' ' Anxiety         '\n",
      " ' Appreciation  ' ' Apprehensive ' ' Arousal       ' ' ArtisticBurst '\n",
      " ' Awe ' ' Awe    ' ' Awe          ' ' Awe           ' ' Bad '\n",
      " ' Betrayal ' ' Betrayal      ' ' Bitter       ' ' Bitterness '\n",
      " ' Bittersweet ' ' Blessed       ' ' Boredom ' ' Boredom         '\n",
      " ' Breakthrough ' ' Calmness     ' ' Calmness      ' ' Captivation '\n",
      " ' Celebration ' ' Celestial Wonder ' ' Challenge ' ' Charm ' ' Colorful '\n",
      " ' Compassion' ' Compassion    ' ' Compassionate ' ' Confidence    '\n",
      " ' Confident ' ' Confusion ' ' Confusion    ' ' Confusion       '\n",
      " ' Connection ' ' Contemplation ' ' Contentment ' ' Contentment   '\n",
      " ' Coziness     ' ' Creative Inspiration ' ' Creativity ' ' Creativity   '\n",
      " ' Culinary Adventure ' ' CulinaryOdyssey ' ' Curiosity ' ' Curiosity  '\n",
      " ' Curiosity   ' ' Curiosity     ' ' Curiosity       ' ' Darkness     '\n",
      " ' Dazzle        ' ' Desolation ' ' Despair ' ' Despair   '\n",
      " ' Despair      ' ' Despair         ' ' Desperation ' ' Determination '\n",
      " ' Determination   ' ' Devastated ' ' Disappointed ' ' Disappointment '\n",
      " ' Disgust ' ' Disgust      ' ' Disgust         ' ' Dismissive '\n",
      " ' DreamChaser   ' ' Ecstasy ' ' Elation   ' ' Elation       '\n",
      " ' Elegance ' ' Embarrassed ' ' Emotion ' ' EmotionalStorm '\n",
      " ' Empathetic ' ' Empowerment   ' ' Enchantment ' ' Enchantment   '\n",
      " ' Energy ' ' Engagement ' ' Enjoyment    ' ' Enthusiasm '\n",
      " ' Enthusiasm    ' ' Envious ' ' Envisioning History ' ' Envy            '\n",
      " ' Euphoria ' ' Euphoria   ' ' Euphoria     ' ' Euphoria      '\n",
      " ' Excitement ' ' Excitement   ' ' Excitement    ' ' Exhaustion '\n",
      " ' Exploration ' ' Fear         ' ' Fearful ' ' FestiveJoy    '\n",
      " ' Free-spirited ' ' Freedom       ' ' Friendship ' ' Frustrated '\n",
      " ' Frustration ' ' Frustration     ' ' Fulfillment  ' ' Fulfillment   '\n",
      " ' Grandeur ' ' Grateful ' ' Gratitude ' ' Gratitude  ' ' Gratitude   '\n",
      " ' Gratitude    ' ' Gratitude     ' ' Grief ' ' Grief      '\n",
      " ' Grief           ' ' Happiness ' ' Happiness    ' ' Happiness     '\n",
      " ' Happy ' ' Harmony ' ' Harmony    ' ' Harmony       ' ' Hate '\n",
      " ' Heartache ' ' Heartbreak ' ' Heartbreak    ' ' Heartwarming '\n",
      " ' Helplessness ' ' Helplessness    ' ' Hope ' ' Hope          '\n",
      " ' Hopeful ' ' Hypnotic ' ' Iconic ' ' Imagination ' ' Immersion '\n",
      " ' Indifference ' ' Indifference    ' ' InnerJourney  ' ' Inspiration '\n",
      " ' Inspiration  ' ' Inspiration   ' ' Inspired ' ' Intimidation '\n",
      " ' Intimidation    ' ' Intrigue      ' ' Isolation ' ' Jealous '\n",
      " ' Jealousy    ' ' Jealousy        ' ' Journey ' ' Joy ' ' Joy          '\n",
      " ' Joy in Baking ' ' JoyfulReunion ' ' Kind         ' ' Kindness '\n",
      " ' Loneliness ' ' Loneliness    ' ' Loneliness      ' ' Loss '\n",
      " ' LostLove ' ' Love ' ' Love         ' ' Marvel       ' ' Melancholy '\n",
      " ' Melancholy      ' ' Melodic       ' ' Mesmerizing ' ' Mindfulness   '\n",
      " ' Miscalculation ' ' Mischievous ' ' Motivation    ' \" Nature's Beauty \"\n",
      " ' Negative  ' ' Neutral ' ' Neutral   ' ' Nostalgia ' ' Nostalgia     '\n",
      " ' Nostalgia      ' ' Nostalgia       ' ' Numbness ' ' Numbness        '\n",
      " ' Obstacle ' \" Ocean's Freedom \" ' Optimism      ' ' Overjoyed     '\n",
      " ' Overwhelmed ' ' Overwhelmed   ' ' Pensive ' ' Playful '\n",
      " ' PlayfulJoy    ' ' Positive ' ' Positive  ' ' Positivity ' ' Pressure '\n",
      " ' Pride ' ' Pride        ' ' Pride         ' ' Proud ' ' Radiance    '\n",
      " ' Radiance      ' ' Reflection ' ' Reflection    ' ' Regret '\n",
      " ' Regret        ' ' Regret         ' ' Rejuvenation ' ' Relief '\n",
      " ' Renewed Effort ' ' Resentment      ' ' Resilience ' ' Resilience   '\n",
      " ' Reverence ' ' Reverence     ' ' Romance ' ' Ruins      '\n",
      " ' Runway Creativity ' ' Sad ' ' Sadness      ' ' Satisfaction '\n",
      " ' Satisfaction  ' ' Serenity ' ' Serenity   ' ' Serenity      '\n",
      " ' Serenity        ' ' Shame ' ' Shame        ' ' Solace ' ' Solitude '\n",
      " ' Sorrow ' ' Sorrow      ' ' Spark        ' ' Success ' ' Suffering '\n",
      " ' Surprise ' ' Surprise     ' ' Surprise      ' ' Suspense ' ' Sympathy '\n",
      " ' Tenderness    ' ' Thrill ' ' Thrill      ' ' Thrill        '\n",
      " ' Thrilling Journey ' ' Touched ' ' Tranquility ' ' Triumph '\n",
      " ' Vibrancy ' ' Whimsy        ' ' Whispers of the Past ' ' Winter Magic '\n",
      " ' Wonder ' ' Wonder     ' ' Wonder       ' ' Wonderment    ' ' Yearning '\n",
      " ' Zest ']\n",
      "Original class distribution: Counter({214: 35, 172: 34, 110: 29, 196: 13, 56: 11, 239: 9, 128: 9, 152: 8, 139: 8, 91: 7, 64: 6, 178: 6, 72: 6, 102: 5, 28: 5, 78: 5, 1: 5, 132: 5, 158: 5, 245: 5, 32: 4, 160: 4, 109: 4, 197: 4, 48: 4, 12: 4, 143: 4, 203: 4, 151: 4, 195: 4, 163: 4, 211: 4, 201: 4, 261: 4, 198: 4, 57: 4, 95: 4, 121: 4, 133: 4, 220: 3, 89: 3, 246: 3, 256: 3, 71: 3, 36: 3, 225: 3, 187: 3, 231: 3, 94: 3, 85: 3, 118: 3, 47: 3, 2: 3, 24: 3, 217: 3, 218: 3, 68: 3, 127: 3, 50: 3, 8: 3, 168: 3, 21: 2, 137: 2, 77: 2, 53: 2, 73: 2, 241: 2, 184: 2, 13: 2, 4: 2, 223: 2, 81: 2, 25: 2, 277: 2, 75: 2, 192: 2, 16: 2, 134: 2, 176: 2, 135: 2, 208: 2, 29: 2, 31: 2, 248: 2, 84: 2, 80: 2, 116: 2, 262: 2, 170: 2, 270: 2, 97: 2, 105: 2, 181: 2, 38: 2, 123: 2, 6: 2, 114: 2, 92: 2, 228: 2, 60: 2, 96: 2, 136: 2, 125: 2, 129: 2, 243: 2, 52: 2, 235: 2, 267: 2, 39: 1, 237: 1, 142: 1, 22: 1, 247: 1, 98: 1, 138: 1, 99: 1, 255: 1, 146: 1, 258: 1, 107: 1, 74: 1, 44: 1, 266: 1, 213: 1, 70: 1, 229: 1, 166: 1, 200: 1, 51: 1, 257: 1, 157: 1, 119: 1, 254: 1, 189: 1, 161: 1, 10: 1, 167: 1, 122: 1, 87: 1, 7: 1, 221: 1, 131: 1, 27: 1, 274: 1, 164: 1, 210: 1, 55: 1, 41: 1, 11: 1, 186: 1, 0: 1, 79: 1, 272: 1, 205: 1, 148: 1, 120: 1, 34: 1, 149: 1, 268: 1, 251: 1, 43: 1, 67: 1, 150: 1, 49: 1, 106: 1, 173: 1, 177: 1, 259: 1, 183: 1, 165: 1, 103: 1, 111: 1, 278: 1, 69: 1, 276: 1, 86: 1, 40: 1, 88: 1, 206: 1, 171: 1, 273: 1, 179: 1, 244: 1, 62: 1, 260: 1, 63: 1, 115: 1, 153: 1, 154: 1, 156: 1, 147: 1, 14: 1, 46: 1, 23: 1, 18: 1, 76: 1, 202: 1, 275: 1, 59: 1, 155: 1, 126: 1, 190: 1, 65: 1, 20: 1, 230: 1, 238: 1, 19: 1, 194: 1, 144: 1, 204: 1, 117: 1, 224: 1, 265: 1, 263: 1, 185: 1, 188: 1, 236: 1, 9: 1, 101: 1, 141: 1, 227: 1, 15: 1, 209: 1, 234: 1, 216: 1, 222: 1, 215: 1, 140: 1, 226: 1, 219: 1, 130: 1, 37: 1, 193: 1, 174: 1, 249: 1, 58: 1, 233: 1, 207: 1, 212: 1, 26: 1, 113: 1})\n",
      "Skipping SMOTE due to insufficient samples in minority class.\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.29931972789115646\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 123, does not match size of target_names, 279. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 87\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Print accuracy and classification report\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(y_test, y_pred))\n\u001b[1;32m---> 87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# Save the vectorizer\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfidf_vectorizer.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2634\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2628\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2629\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2630\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[0;32m   2631\u001b[0m             )\n\u001b[0;32m   2632\u001b[0m         )\n\u001b[0;32m   2633\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2634\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2635\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2636\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2637\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[0;32m   2638\u001b[0m         )\n\u001b[0;32m   2639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2640\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 123, does not match size of target_names, 279. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import re\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load your dataset\n",
    "file_path = r'C:\\Users\\asshe\\Desktop\\Sentiment analysis\\sentimentdataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean the 'Text' column\n",
    "def preprocess_text(text):\n",
    "    cleaned_text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    cleaned_text = re.sub(r'\\@\\w+|\\#', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', cleaned_text)\n",
    "    cleaned_text = cleaned_text.lower().split()\n",
    "    cleaned_text = [word for word in cleaned_text if word not in stopwords.words('english')]\n",
    "    cleaned_text = ' '.join(cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "df['Cleaned_Text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Encode the sentiment labels\n",
    "le = LabelEncoder()\n",
    "df['Encoded_Sentiment'] = le.fit_transform(df['Sentiment'])\n",
    "print(le.classes_)  # Print out the classes to ensure correct encoding\n",
    "\n",
    "# Vectorize the cleaned text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['Cleaned_Text'])\n",
    "\n",
    "# Define the target variable\n",
    "y = df['Encoded_Sentiment']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check class distribution before applying SMOTE\n",
    "print(f\"Original class distribution: {Counter(y_train)}\")\n",
    "\n",
    "# Handle class imbalance using SMOTE, adjust k_neighbors if necessary\n",
    "if len(Counter(y_train)) > 1 and min(Counter(y_train).values()) > 1:\n",
    "    smote = SMOTE(random_state=42, k_neighbors=min(5, min(Counter(y_train).values()) - 1))\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    print(f\"Resampled class distribution: {Counter(y_train_resampled)}\")\n",
    "else:\n",
    "    print(\"Skipping SMOTE due to insufficient samples in minority class.\")\n",
    "    X_train_resampled, y_train_resampled = X_train, y_train\n",
    "\n",
    "# Set up RandomForest model with hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Best model\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "# Save the vectorizer\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)\n",
    "\n",
    "# Save the model\n",
    "with open('sentiment_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_rf_model, file)\n",
    "\n",
    "# Load the vectorizer\n",
    "with open('tfidf_vectorizer.pkl', 'rb') as file:\n",
    "    loaded_vectorizer = pickle.load(file)\n",
    "\n",
    "# Load the model\n",
    "with open('sentiment_model.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Function to predict sentiment\n",
    "def predict_sentiment(new_statement):\n",
    "    cleaned_statement = preprocess_text(new_statement)\n",
    "    transformed_statement = loaded_vectorizer.transform([cleaned_statement])\n",
    "    prediction = loaded_model.predict(transformed_statement)\n",
    "    sentiment_label = le.inverse_transform(prediction)\n",
    "    return sentiment_label[0]\n",
    "\n",
    "# Example usage\n",
    "test_statements = [\n",
    "    \"I love this product!\",\n",
    "    \"This is the worst thing ever.\",\n",
    "    \"Absolutely fantastic!\",\n",
    "    \"I hate this product.\"\n",
    "]\n",
    "\n",
    "for statement in test_statements:\n",
    "    print(f\"Statement: {statement}\")\n",
    "    print(f\"Predicted Sentiment: {predict_sentiment(statement)}\")\n",
    "\n",
    "# Function to predict sentiment with probability\n",
    "def predict_sentiment_with_proba(new_statement):\n",
    "    cleaned_statement = preprocess_text(new_statement)\n",
    "    transformed_statement = loaded_vectorizer.transform([cleaned_statement])\n",
    "    prediction_proba = loaded_model.predict_proba(transformed_statement)\n",
    "    sentiment_label = le.inverse_transform([prediction_proba.argmax()])\n",
    "    return sentiment_label[0], prediction_proba\n",
    "\n",
    "# Example usage with probabilities\n",
    "new_statement = \"I hate this product!\"\n",
    "predicted_sentiment, proba = predict_sentiment_with_proba(new_statement)\n",
    "print(f\"The predicted sentiment for the statement is: {predicted_sentiment}\")\n",
    "print(f\"Prediction probabilities: {proba}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be2f624e-d077-4113-8368-7853948a4949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID         Game Sentiment  \\\n",
      "0  2401  Borderlands  Positive   \n",
      "1  2401  Borderlands  Positive   \n",
      "2  2401  Borderlands  Positive   \n",
      "3  2401  Borderlands  Positive   \n",
      "4  2401  Borderlands  Positive   \n",
      "\n",
      "                                                Text  \n",
      "0  im getting on borderlands and i will murder yo...  \n",
      "1  I am coming to the borders and I will kill you...  \n",
      "2  im getting on borderlands and i will kill you ...  \n",
      "3  im coming on borderlands and i will murder you...  \n",
      "4  im getting on borderlands 2 and i will murder ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8189730200174065\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.84      0.74      0.79      2592\n",
      "    Negative       0.85      0.86      0.85      4519\n",
      "     Neutral       0.84      0.78      0.81      3596\n",
      "    Positive       0.76      0.86      0.81      4230\n",
      "\n",
      "    accuracy                           0.82     14937\n",
      "   macro avg       0.82      0.81      0.81     14937\n",
      "weighted avg       0.82      0.82      0.82     14937\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a statement to analyze its sentiment:  i love this product\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment for 'i love this product' : Positive 😊\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the column names based on the structure observed\n",
    "column_names = ['ID', 'Game', 'Sentiment', 'Text']\n",
    "\n",
    "# Load the dataset with correct column names and delimiters\n",
    "df = pd.read_csv(r'C:\\Users\\asshe\\Desktop\\Sentiment analysis\\twitter_training.csv', delimiter=',', names=column_names, quotechar='\"')\n",
    "\n",
    "# Display the first few rows to confirm the correct structure\n",
    "print(df.head())\n",
    "\n",
    "# Handle NaN values in the 'Text' column by filling them with an empty string\n",
    "df['Text'] = df['Text'].fillna('')\n",
    "\n",
    "# Preprocess the data\n",
    "# Convert text to lowercase (you can add more preprocessing steps as needed)\n",
    "df['Text'] = df['Text'].str.lower()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vect, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_vect)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Predict the sentiment of a new statement\n",
    "def predict_sentiment(new_statement):\n",
    "    new_statement_vect = vectorizer.transform([new_statement])\n",
    "    prediction = model.predict(new_statement_vect)\n",
    "    return prediction[0]\n",
    "\n",
    "# Map sentiment to emoji\n",
    "def sentiment_to_emoji(sentiment):\n",
    "    if sentiment == 'Positive':\n",
    "        return '😊'\n",
    "    elif sentiment == 'Negative':\n",
    "        return '😐'\n",
    "    else:\n",
    "        return '😐'  # Default to neutral emoji for unknown sentiment\n",
    "\n",
    "# Get user input\n",
    "user_input = input(\"Enter a statement to analyze its sentiment: \")\n",
    "\n",
    "# Predict the sentiment of the user's input\n",
    "predicted_sentiment = predict_sentiment(user_input)\n",
    "predicted_emoji = sentiment_to_emoji(predicted_sentiment)\n",
    "\n",
    "print(\"Predicted Sentiment for '{}' : {} {}\".format(user_input, predicted_sentiment, predicted_emoji))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e11bb-61e5-492a-bc9f-55ad936609aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
